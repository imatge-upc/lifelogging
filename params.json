{
  "name": "Lifelogging",
  "tagline": "Tools for lifelogging image processing.",
  "body": "# EgoMemNet: Visual Memorability Adaptation to Egocentric Images\r\n\r\n| ![Marc Carné][MarcCarne-photo]  | ![Xavier Giro-i-Nieto][XavierGiro-photo]   | ![CathalGurrin][CathalGurrin-photo]  |\r\n|:-:|:-:|:-:|:-:|:-:|\r\n| Marc Carné  | [Xavier Giro-i-Nieto][XavierGiro-web]   | [Cathal Gurrin][CathalGurrin-web]   |\r\n\r\n[CathalGurrin-web]: https://www.insight-centre.org/users/cathal-gurrin\r\n[XavierGiro-web]: https://imatge.upc.edu/web/people/xavier-giro\r\n\r\n[MarcCarne-photo]: ./authors/MarcCarne.jpg \"Marc Carné\"\r\n[CathalGurrin-photo]: ./authors/CathalGurrin.jpg \"Cathal Gurrin\"\r\n[XavierGiro-photo]: ./authors/XavierGiro.jpg \"Xavier Giro-i-Nieto\"\r\n\r\nA joint collaboration between:\r\n\r\n| ![logo-insight] | ![logo-dcu] | ![logo-upc] | \r\n|:-:|:-:|:-:|:-:|\r\n| [Insight Centre for Data Analytics][insight-web] | [Dublin City University (DCU)][dcu-web]  |[Universitat Politecnica de Catalunya (UPC)][upc-web]   | \r\n\r\n[insight-web]: https://www.insight-centre.org/\r\n[dcu-web]: http://www.dcu.ie/\r\n[upc-web]: http://www.upc.edu/?set_language=en\r\n[gpi-web]: https://imatge.upc.edu/web/\r\n\r\n[logo-insight]: ./logos/insight.jpg \"Insight Centre for Data Analytics\"\r\n[logo-dcu]: ./logos/dcu.png \"Dublin City University\"\r\n[logo-upc]: ./logos/upc.jpg \"Universitat Politecnica de Catalunya\"\r\n\r\n\r\n\r\n\r\n\r\n## Abstract\r\n\r\nThis work explores the adaptation of visual memorability prediction for photos intentionally captured by handheld cameras, to images passively captured from an egocentric point of view by wearable cameras.\r\nThe estimation of a visual memorability score for an egocentric images is a valuable cue when filtering among the large amount of photos generated by wearable cameras.\r\nOur work illustrates that state of the art techniques on visual memorability prediction require an adaptation to egocentric vision to achieve acceptable level of performance.\r\nFor this purpose, a new annotation tool and annotated dataset are presented.\r\nThis training data has been used to fine-tune a pre-trained convolutional neural network by means of a novel temporally-driven data augmentation technique.\r\n\r\n## Publication\r\n\r\nAcceptance pending.\r\n\r\n## Qualitative Results\r\n\r\n![Memorability scores](./figs/comparative_3.jpg)\r\n\r\n## EgoMemNet\r\n\r\nYou can download our best model, EgoMemNet, from [here](https://imatge.upc.edu/web/sites/default/files/projects/1634/public/egocentric/2016-egomemnet/EgoMemNet.caffemodel).\r\n\r\nAs explained in our paper, our networks were trained on the training and validation data provided by Insight dataset, created for this work.Three different strategies used in data augmentation to avoid overfitting during fine-tunning:\r\n* No augmentation.\r\n* Spatial data augmentation (SDA), 10 transformations per image: cetral crop, four corners and their correspondent x-axis flips.\r\n* Temporal data augmentation (TDA), similar temporal neighbours.\r\n\r\nThe provided model was developed over [Caffe](http://caffe.berkeleyvision.org/) by [Berkeley Vision and Learning Center (BVLC)](http://bvlc.eecs.berkeley.edu/). You will need to follow [these instructions](http://caffe.berkeleyvision.org/installation.html) to install Caffe.\r\n\r\n## Visual Memory game\r\nThe visual memory game for annotation proposed in this work is online available [here](http://imatge.upc.edu:8000). It is important to open the game in a CHROME browser.\r\n\r\n### Game Features\r\n* 9 minuts task.\r\n* Users must press 'd' when repetition of an image is detected.\r\n* Output: text file, downloaded in the client machine (downloads local folder).\r\n\r\n### Game Technical Features\r\n\r\nThis game has been inspired in the game from MIT to replicate the results, because the code for the game are not available.\r\nIn that game there are two types of images: the first one are images that we want to detect and annotate, called targets. The second type are the fillers, images that goes between targets. Some of these fillers are vigilance fillers, randomly selected, but them function is to control that user are doing the work well.\r\nTargets can only appear twice and fillers have no limit of shows.\r\n\r\nThe repetition of targets are between 8 and 40 images (without count blank frame, and the images between the repetition can be other targets or fillers). The sequence of images also has a blank frame with the function of focusing user attention in the center of the image. This attention frame contains a small black square at the center of a white background.\r\nBetween targets, fillers are added and the number of these fillers is between 0 and 3 randomly selected.\r\n\r\nThis game is a web application developed in HTML code for the instructions and show the image. The algorithm that make image sequence is in JavaScript. Both codes are linked and variables are shared between them. The output of the game is a text file where each line corresponds to an image and there are different values separated by comas. The first value corresponds to the image name to identify it. The second value means if the image has been shown during the game. If the value is equal to 1, the image has been shown and the next two values corresponds to the first and second time of view (in number of frames from the begin). The last value is equal to 1 if the user have detected the image at his repetition.\r\n\r\nThe last line of the file corresponds to user statistics based on user attention. Using the vigilance fillers that we supervise, we can identify how many vigilance fillers have been detected. We do a detection rate and if this rate is equal or high than 0.5 we use this results for annotate the image.\r\n\r\nThe same collection of images is shown in a random order to a team of annotators, whose goal is to detect all repetitions.\r\n\r\nOur choice of targets and fillers should not contain images which are too similar and that could confuse the annotator.\r\n\r\nThe Insight dataset contains 50 images used as targets for the annotation tool. These images were captured with an Autographer wearable camera, together with the wearer's heart rate and galvanic skin response.  \r\nThis dataset was built from a uniform sampling from a lifelogging record of 25 days, which corresponds to 16,000 imatges.\r\n\r\nThe UTEgocentric dataset (Grauman et al.) contains 4 videos from head-mounted cameras, each about 3-5 hours long, captured in a very uncontrolled setting.\r\nThe videos were sampled, extracting frames at a fixed interval of time, in this case every 30 seconds, to simulate the capture by an low sampling rate camera. The appearance of these frames is similar to the Anonymous dataset, in this way, we can help to reduce the probability that any filler image is similar to a target images, yet retaining the egocentric-nature of the images. The number of filler images is 540, much higher than the number of targets in order to achieve a non-repetition of fillers and focus user attention to targets.\r\n\r\n\r\n\r\n## Technical support\r\n\r\nWe would like to especially thank Albert Gil Moreno and Josep Pujal from our technical support team at the Image Processing Group at the UPC.\r\n\r\n| ![AlbertGil-photo]  | ![JosepPujal-photo]  |\r\n|:-:|:-:|\r\n| [Albert Gil](AlbertGil-web)  |  [Josep Pujal](JosepPujal-web) |\r\n\r\n[AlbertGil-photo]: ./authors/AlbertGil.jpg \"Albert Gil\"\r\n[JosepPujal-photo]: ./authors/JosepPujal.jpg \"Josep Pujal\"\r\n\r\n[AlbertGil-web]: https://imatge.upc.edu/web/people/albert-gil-moreno\r\n[JosepPujal-web]: https://imatge.upc.edu/web/people/josep-pujal\r\n\r\n## Acknowledgements\r\n\r\n| ![logo-ajterrassa] | ![logo-erasmus] | ![logo-cst] |\r\n|:-:|:-:|:-:|\r\n| [Ajuntament de Terrassa][ajterrassa-web] | [Erasmus +][erasmus-web]  |[Consorci Sanitari de Terrassa (CST)][cst-web]   |\r\n\r\n[ajterrassa-web]: https://www.terrassa.cat\r\n[erasmus-web]: http://www.oapee.es/oapee/inicio/ErasmusPlus.html\r\n[cst-web]: http://www.cst.cat\r\n\r\n[logo-ajterrassa]: ./logos/ajterrassa.jpg \"Ajuntament de Terrassa\"\r\n[logo-erasmus]: ./logos/erasmus.jpg \"Erasmus +\"\r\n[logo-cst]: ./logos/cst.jpg \"Consorci Sanitari de Terrassa\"\r\n\r\n## Contact\r\n\r\nIf you have any general doubt about our work or code which may be of interest for other researchers, please drop us an e-mail at <mailto:marc.carne.herrera@estudiant.upc.edu> or <mailto:xavier.giro@upc.edu>.\r\n\r\n\r\n",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}